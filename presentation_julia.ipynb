{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## You don't know what to choose between Matlab and Python :\n",
    "\n",
    "# Try \n",
    "\n",
    "<center><img src=\"figs/julialogo-smaller.png\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Play with the slides \n",
    "\n",
    "https://mybinder.org/v2/gh/raphbacher/julia-intro/master?filepath=presentation_julia.ipynb\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://github.com/raphbacher/julia-intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "- State of the art : the two language problem\n",
    "- What is Julia\n",
    "- Why Julia is fast\n",
    "- Julia Ecosystem & interop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matlab\n",
    "\n",
    "Pros :\n",
    "- Polished product with support\n",
    "- Simulink\n",
    "- High level syntax\n",
    "\n",
    "Cons :\n",
    "- Closed : not everyone has access to it, impossible to put a demonstrator online.\n",
    "- Slow loops (better since 2015) : not everything is pretty once vectorized\n",
    "- Not fast per se (Fortran bindings), memory management is difficult\n",
    "- Not a generalist language (cumbersome to put a demo on the web e.g.)\n",
    "- 12K€ each year at Gipsa-lab\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python\n",
    " \n",
    "Pros :\n",
    "- Free and open-source, generalist, widly used outside scientific community\n",
    "- Lot of scientific communities are embracing it\n",
    "- Lots of efforts to make it fast (numba, ...)\n",
    "\n",
    "Cons :\n",
    "- Scientific computing is not native : \n",
    "    - all fallback to C/Fortran black-boxes -> limit flexibility \n",
    "- Object Oriented paradigm can be cumbersome for scientific code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Science and the two languages problem\n",
    "\n",
    "Scientists need to easily explore new ideas :\n",
    "\n",
    "- Need for mathematical abstractions\n",
    "- Need for customizations (avoid black boxes, try variations)\n",
    "\n",
    "- But also need for performance (intrinsic goal or to allow re-use)\n",
    "\n",
    "What is done now (when you need to go further than using existing packages, for e.g. data analysis)\n",
    "\n",
    "1) Prototyping in R/Python/Matlab\n",
    "\n",
    "2) Rewriting whole or parts (if money/man power) to a performant low-level language as C/Fortran\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Yet another language\n",
    "\n",
    "<center><img src=\"https://imgs.xkcd.com/comics/standards.png\" style=\"width:60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Here comes Julia :\n",
    "\n",
    "* innovative open-source generalist programming language with scientific computing at its core\n",
    "* **easy as Matlab, fast as Fortran, flexible as Python, deep as LISP**\n",
    "* leverages (for now...) major C/Fortran science packages, e.g. LAPACK, MPI, FFTW... \n",
    "* 5th language to run at 1 petaflops (Celeste project), after assembly, Fortran, C, C++ \n",
    "* State of the art packages in Optimization (JUMP), Differential Equations (DifEq), ... Well positioned for ML (Flux, Knet, autodiff...)\n",
    "* solves the \"two-languages problem\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Background\n",
    "\n",
    "* origins at MIT, UCSB applied math & computer science, 2010     \n",
    "* founders Viral Shah, Jeff Bezanson, Stefan Karpinsky (now at Julia Computing LLC), Alan Edelman (MIT)\n",
    "* ~10-person core language team, ~870 contributors, ~2500 registered packages \n",
    "* support from Intel, Microsoft, Wall St., Moore Foundation, NumFocus\n",
    "* julia-0.1 released in 2012, julia-1.0 in August 2018, now julia-1.2\n",
    "\n",
    "\n",
    "**Its goal : Solve the two-languages problem by having a dynamic, high level language with good mathematical expressivity able to be as fast as C/Fortran.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Disclaimer\n",
    "\n",
    "- I am not a Julia expert : I've been following the language for ~ two years and I am currently porting python research codes to Julia.\n",
    "- Julia (like Python...) is not a drop-in replacement for Matlab, it is an alternative.\n",
    "- Don't fix that ain't broken : \n",
    "    - if Matlab/R/Python/C is good for you, no need to change\n",
    "    - but if you are sometimes faced with some limitations of these languages, give Julia a try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia: expressive as Matlab\n",
    "\n",
    "Julia can as expressive as Matlab for interactive calculations with built-in numerical libraries and plotting. A few examples...\n",
    "\n",
    "### Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       "  0.381676  -1.04426   -0.534385   -0.00452359\n",
       " -1.61989    0.123169  -0.0742699   1.22578   \n",
       "  0.45197   -1.50902   -2.14702    -0.165843  \n",
       " -1.60445   -1.36613    1.12571    -0.560196  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = randn(4,4)       # 4 x 4 matrix of normally distributed random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       "  0.38167565607252124\n",
       " -1.61988750100453   \n",
       "  0.4519702201213353 \n",
       " -1.6044521050640805 "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:,1]                # familiar colon syntax --extract first column of A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3306690738754696e-16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "b = randn(4)          \n",
    "x = A\\b               # solve Ax=b for x using backslash operator\n",
    "norm(A*x-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "U, σ, V = svd(A);     # singular value decomposition --note unicode variable name σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5361623105693727e-15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Σ = diagm(0 => σ)\n",
    "norm(A - U*Σ*V')      # compute error of SVD factorization A = U Σ V'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fast as Fortran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.004917 seconds (20.83 k allocations: 1.173 MiB)\n",
      "  0.000001 seconds (4 allocations: 160 bytes)\n"
     ]
    }
   ],
   "source": [
    "function loop()\n",
    "    a=0 \n",
    "    for i in 1:1_000_000\n",
    "        a+=1;\n",
    "    end\n",
    "end\n",
    "@time loop() # compile time\n",
    "@time loop() # now fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compare with Matlab (R2018) \n",
    "\n",
    "*I know this is not Matlab-friendly, that's the point !*\n",
    "\n",
    "    function [] = loop()\n",
    "        a=0;\n",
    "        for i=1:1000000\n",
    "            a=i+1;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    f = @() loop();\n",
    "    \n",
    "    timeit(f) => 0.0018s\n",
    "\n",
    "**1000x slower !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Benchmarks on common code pattterns\n",
    "\n",
    "Takeaway: Julia timings are clustered around C timing, Matlab/Python/R orders of magnitude slower.\n",
    "\n",
    "<center><img src=\"files/figs/benchmarks.png\" width=70%/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### KS-CNAB2 benchmark: CPU time versus lines of code \n",
    "\n",
    "Takeaway: The Julia PDE code is almost as compact as Matlab/Python, almost as fast as C/Fortran.\n",
    "<center><img src=\"files/figs/ks_cpu_vs_lines_1024.png\" width=70%/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Julia: easy, dynamic, and fast. How? \n",
    "\n",
    "\n",
    " * **Just-in-time compilation** (JIT)\n",
    "    - user-level code is compiled to machine code on-the-fly  \n",
    "    \n",
    "    \n",
    " * **Meticulous type system**\n",
    "    - designed to maximize impact of JIT\n",
    "    - type inference: compiler determines types of variables\n",
    "    \n",
    "    \n",
    " * **Multiple dispatch**\n",
    "    - functions are compiled for each set of argument types\n",
    "    - function dispatch determined at compile time when possible, run time when not\n",
    " \n",
    "\n",
    "**Just-in-time ahead-of-time compilation\n",
    "\n",
    "Functions are compiled to machine code when first run. Subsequent runs are as fast as compiled C, C++, Fortran.\n",
    "Not a tracing JIT (like pypy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Caveats\n",
    "\n",
    "- It's a marathon not a sprint : Julia can be slow at first\n",
    "- It's an open-source language with lots of good willing contributors, it's not a product (see JuliaPro...)\n",
    "- If you directly translate from Matlab to Julia you will not always see an improvement, you have exploit Julia strengths (loops to avoid allocations, type stability, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A julia type\n",
    "\n",
    "Like a C struct, or a Python object... but without methods\n",
    "\n",
    "```julia\n",
    "struct Spaceship\n",
    "           speed::Float64\n",
    "           Position::Array{Float64,2}\n",
    "   end\n",
    "```\n",
    "\n",
    "## Multiple dispatch\n",
    "\n",
    "```julia\n",
    "collide(a::Asteroid, s::Spaceship) # a first method of the function collide\n",
    "collide(s1::Spaceship, s2::Spaceship) # another method of the function collide\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The power of Multiple dispatch\n",
    "\n",
    "Ref https://medium.com/@Jernfrost/defining-custom-units-in-julia-and-python-513c34a4c971\n",
    "\n",
    "See also (very interesting!) : https://www.youtube.com/watch?v=kc9HwsxE1OY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "abstract type Temperature end\n",
    "\n",
    "struct Celsius <: Temperature\n",
    "    value\n",
    "end\n",
    "\n",
    "struct Kelvin <: Temperature\n",
    "   value::Float64 \n",
    "end\n",
    "\n",
    "struct Fahrenheit <: Temperature\n",
    "    value::Float64\n",
    "end\n",
    "\n",
    "import Base: promote_rule, convert\n",
    "promote_rule(::Type{Kelvin}, ::Type{Celsius})     = Kelvin\n",
    "promote_rule(::Type{Fahrenheit}, ::Type{Celsius}) = Celsius\n",
    "promote_rule(::Type{Fahrenheit}, ::Type{Kelvin})  = Kelvin\n",
    "\n",
    "convert(::Type{Kelvin},  t::Celsius)     = Kelvin(t.value + 273.15)\n",
    "convert(::Type{Kelvin},  t::Fahrenheit)  = Kelvin(Celsius(t))\n",
    "convert(::Type{Celsius}, t::Kelvin)      = Celsius(t.value - 273.15)\n",
    "convert(::Type{Celsius}, t::Fahrenheit)  = Celsius((t.value - 32)*5/9)\n",
    "convert(::Type{Fahrenheit}, t::Celsius)  = Fahrenheit(t.value*9/5 + 32)\n",
    "convert(::Type{Fahrenheit}, t::Kelvin)   = Fahrenheit(Celsius(t))\n",
    "\n",
    "import Base: +,-,*\n",
    "+(x::T, y::T) where {T <: Temperature} = T(x.value + y.value)\n",
    "-(x::T, y::T) where {T <: Temperature} = T(x.value - y.value)\n",
    "\n",
    "+(x::Temperature, y::Temperature) = +(promote(x,y)...)\n",
    "-(x::Temperature, y::Temperature) = -(promote(x,y)...)\n",
    "\n",
    "*(x::Number, y::T) where {T <: Temperature} = T(x * y.value)\n",
    "\n",
    "const °C = Celsius(1); const °F = Fahrenheit(1); const K = Kelvin(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kelvin(275.15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1K+1°C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introspection \n",
    "$$f(x) = 4\\, x\\, (1-x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.008524 seconds (18.00 k allocations: 1.002 MiB)\n",
      "  0.000002 seconds (5 allocations: 176 bytes)\n"
     ]
    }
   ],
   "source": [
    "f(x) = 4x*(1-x)     # define logistic map\n",
    "@time f(0.3);       # first run is slow\n",
    "@time f(0.4);       # second run is a thousand times faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Observe the compilation of $f(x)$ by stages\n",
    "\n",
    "user Julia -> generic Julia expression -> typed Julia expression -> intermediate compiler language -> machine code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "include(\"macros.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m %1 = 4 * x\n",
       "\u001b[90m│  \u001b[39m %2 = 1 - x\n",
       "\u001b[90m│  \u001b[39m %3 = %1 * %2\n",
       "\u001b[90m└──\u001b[39m      return %3\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@code_lowered f(0.3)  # show f(x) as generic Julia expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m %1 = (Base.mul_float)(4.0, x)\u001b[36m::Float64\u001b[39m\n",
       "\u001b[90m│  \u001b[39m %2 = (Base.sub_float)(1.0, x)\u001b[36m::Float64\u001b[39m\n",
       "\u001b[90m│  \u001b[39m %3 = (Base.mul_float)(%1, %2)\u001b[36m::Float64\u001b[39m\n",
       "\u001b[90m└──\u001b[39m      return %3\n",
       ") => Float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@code_typed f(0.3)    # show f(x) as Julia expr with inferred types, based on the arg types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ";  @ In[10]:1 within `f'\n",
      "define double @julia_f_12923(double) {\n",
      "top:\n",
      "; ┌ @ promotion.jl:314 within `*' @ float.jl:399\n",
      "   %1 = fmul double %0, 4.000000e+00\n",
      "; └\n",
      "; ┌ @ promotion.jl:315 within `-' @ float.jl:397\n",
      "   %2 = fsub double 1.000000e+00, %0\n",
      "; └\n",
      "; ┌ @ float.jl:399 within `*'\n",
      "   %3 = fmul double %1, %2\n",
      "; └\n",
      "  ret double %3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm f(0.3)    # show f(x) in intermediate compiler language (LLVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Type inference and dispatch\n",
    "\n",
    "We can see that if we call f on an Integer we get a code specialised for integer (i64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.text\n",
      "; ┌ @ In[10]:1 within `f'\n",
      "\tmovabsq\t$140669597427496, %rax  # imm = 0x7FF03162A728\n",
      "; │┌ @ promotion.jl:314 within `*' @ float.jl:399\n",
      "\tvmulsd\t(%rax), %xmm0, %xmm1\n",
      "\tmovabsq\t$140669597427504, %rax  # imm = 0x7FF03162A730\n",
      "; │└\n",
      "; │┌ @ promotion.jl:315 within `-' @ float.jl:397\n",
      "\tvmovsd\t(%rax), %xmm2           # xmm2 = mem[0],zero\n",
      "\tvsubsd\t%xmm0, %xmm2, %xmm0\n",
      "; │└\n",
      "; │┌ @ float.jl:399 within `*'\n",
      "\tvmulsd\t%xmm0, %xmm1, %xmm0\n",
      "; │└\n",
      "\tretq\n",
      "\tnopw\t%cs:(%rax,%rax)\n",
      "; └\n"
     ]
    }
   ],
   "source": [
    "@code_native f(0.3) # show f(x) in IA-64 assembly language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.text\n",
      "; ┌ @ In[10]:1 within `f'\n",
      "; │┌ @ In[10]:1 within `-'\n",
      "\tmovl\t$1, %eax\n",
      "\tsubq\t%rdi, %rax\n",
      "; │└\n",
      "; │┌ @ int.jl:54 within `*'\n",
      "\timulq\t%rdi, %rax\n",
      "\tshlq\t$2, %rax\n",
      "; │└\n",
      "\tretq\n",
      "\tnopw\t%cs:(%rax,%rax)\n",
      "; └\n"
     ]
    }
   ],
   "source": [
    "@code_native f(3)    # show f(x) in IA-64 assembly language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Genericity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "function inner_sum(A,vs)\n",
    "    t = zero(eltype(A))\n",
    "    for v in vs\n",
    "        t += inner(v,A,v)\n",
    "    end\n",
    "    return t\n",
    "end\n",
    "\n",
    "inner(v,A,w) = dot(v,A*w)\n",
    "\n",
    "## Now we want a new type the famous One Hot Vector\n",
    "\n",
    "import Base: *\n",
    "\n",
    "struct OneHotVector <: AbstractVector{Bool}\n",
    "  idx::UInt32\n",
    "  len::UInt32\n",
    "end\n",
    "\n",
    "Base.size(xs::OneHotVector) = (Int64(xs.len),)\n",
    "Base.getindex(xs::OneHotVector, i::Integer) = i == xs.idx\n",
    "Base.getindex(xs::OneHotVector, ::Colon) = OneHotVector(xs.idx, xs.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.034809 seconds (105 allocations: 793.922 KiB)\n",
      "  0.000003 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.18336107274835"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It works (generic) ! but it's slow\n",
    "v = [OneHotVector(i,1000) for i in rand(1:1000,100)]\n",
    "A=rand(1000,1000)\n",
    "\n",
    "inner_sum(A,v)\n",
    "@time inner_sum(A,v)\n",
    "\n",
    "# And now specify to get speed !\n",
    "A::AbstractMatrix * b::OneHotVector = A[:, b.idx]\n",
    "inner(v::OneHotVector,A,w::OneHotVector) = A[v.idx,w.idx] # How to you do that in single dispatch ?\n",
    "\n",
    "inner_sum(A,v)\n",
    "@time inner_sum(A,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From prototype to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.109357 seconds (5 allocations: 176 bytes)\n",
      "  0.056278 seconds (5 allocations: 176 bytes)\n",
      "  0.063654 seconds (5 allocations: 176 bytes)\n",
      "  0.048493 seconds (15 allocations: 688 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=rand(100_000_000)\n",
    "\n",
    "function simple_sum(a)\n",
    "    res = 0\n",
    "    for i in eachindex(a)\n",
    "        res += a[i]\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "simple_sum(a)\n",
    "@time simple_sum(a)\n",
    "\n",
    "function simd_sum(a)\n",
    "    res = zero(eltype(a)) # note the type instability of res=0\n",
    "    @simd for i in eachindex(a)\n",
    "        @inbounds res += a[i]\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "simd_sum(a)\n",
    "@time simd_sum(a)\n",
    "sum(a)\n",
    "@time sum(a)\n",
    "\n",
    "using PyCall\n",
    "np = pyimport(\"numpy\")\n",
    "np.sum(a)\n",
    "@time np.sum(a)\n",
    "\n",
    "using Test\n",
    "@test np.sum(a)≈simd_sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An ecosystem of packages\n",
    "\n",
    "- Most of packages are available on Github (easy collaboration)\n",
    "- Main fields are grouped in Github Organizations (see https://julialang.org/community/)\n",
    "- Julia comes with a powerful package/environment manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/raphael/Projets/Perso/tests-julia/julia-intro/Project.toml\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg #load the Pkg stdlib\n",
    "Pkg.activate(\".\") #activate the local environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solving Differential Equations\n",
    "\n",
    " Solve the Lorenz equations:\n",
    " \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dx}{dt} &= σ(y-x) \\\\\n",
    "\\frac{dy}{dt} &= x(ρ-z) - y \\\\\n",
    "\\frac{dz}{dt} &= xy - βz \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div style=\"padding: 20px;background-color: #f44336;color: white; margin-bottom: 15px;\">\n",
    "Fair Warning ⚠ : the next cell is gonna take some time. Like really. You can go grab a coffee.\n",
    "\n",
    "This compilation time only occurs the first time you load this version of this package on your machine. \n",
    "If you are trying this online on Mybinder, remember that each time you connect, you are on a fresh julia install \n",
    "just built for you, so this precompilation time occurs. And Plots and DifferentialEquations are pretty big libraries (DifEq regroups a lot of solvers).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"DifferentialEquations\") # add the Differential equation suite\n",
    "using DifferentialEquations # first time is very slow (precompilation)\n",
    "using Plots\n",
    "plotlyjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "function lorenz(du,u,p,t)\n",
    " du[1] = 10.0*(u[2]-u[1])\n",
    " du[2] = u[1]*(28.0-u[3]) - u[2]\n",
    " du[3] = u[1]*u[2] - (8/3)*u[3]\n",
    "end\n",
    "\n",
    "u0 = [1.0;0.0;0.0] ; tspan = (0.0,100.0);\n",
    "prob = ODEProblem(lorenz,u0,tspan)\n",
    "sol = DifferentialEquations.solve(prob)\n",
    "Plots.plot(sol,vars=(1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using JuMP, GLPK, Test\n",
    "\n",
    "\"\"\"\n",
    "Formulate and solve a simple LP:\n",
    "    max 5x + 3y\n",
    "     st 1x + 5y <= 3\n",
    "         0 <= x <= 2\n",
    "         0 <= y <= 30\n",
    "\"\"\"\n",
    "function example_basic()\n",
    "    model = Model(with_optimizer(GLPK.Optimizer))\n",
    "\n",
    "    @variable(model, 0 <= x <= 2)\n",
    "    @variable(model, 0 <= y <= 30)\n",
    "\n",
    "    @objective(model, Max, 5x + 3y)\n",
    "    @constraint(model, 1x + 5y <= 3.0)\n",
    "\n",
    "    println(model)\n",
    "    JuMP.optimize!(model)\n",
    "\n",
    "    obj_value = JuMP.objective_value(model)\n",
    "    x_value = JuMP.value(x)\n",
    "    y_value = JuMP.value(y)\n",
    "\n",
    "    println(\"Objective value: \", obj_value)\n",
    "    println(\"x = \", x_value)\n",
    "    println(\"y = \", y_value)\n",
    "    @test obj_value ≈ 10.6\n",
    "    @test x_value ≈ 2\n",
    "    @test y_value ≈ 0.2\n",
    "\n",
    "end\n",
    "\n",
    "example_basic()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Composability\n",
    "\n",
    "See https://tutorials.juliadiffeq.org/html/type_handling/02-uncertainties.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using DifferentialEquations, Measurements, Plots\n",
    "\n",
    "g = 9.79 ± 0.02; # Gravitational constants\n",
    "L = 1.00 ± 0.01; # Length of the pendulum\n",
    "\n",
    "#Initial Conditions\n",
    "u₀ = [0 ± 0, π / 60 ± 0.01] # Initial speed and initial angle\n",
    "tspan = (0.0, 6.3)\n",
    "\n",
    "#Define the problem\n",
    "function simplependulum(du,u,p,t)\n",
    "    θ  = u[1]\n",
    "    dθ = u[2]\n",
    "    du[1] = dθ\n",
    "    du[2] = -(g/L)*θ\n",
    "end\n",
    "\n",
    "#Pass to solvers\n",
    "prob = ODEProblem(simplependulum, u₀, tspan)\n",
    "sol = solve(prob, Tsit5(), reltol = 1e-6)\n",
    "\n",
    "# Analytic solution\n",
    "u = u₀[2] .* cos.(sqrt(g / L) .* sol.t)\n",
    "\n",
    "plot(sol.t, getindex.(sol.u, 2), label = \"Numerical\")\n",
    "plot!(sol.t, u, label = \"Analytic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automatic differentiation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"ForwardDiff\")\n",
    "using ForwardDiff\n",
    "\n",
    "f(x::Vector) = sum(sin, x) + prod(tan, x) * sum(sqrt, x);\n",
    "\n",
    "x = rand(5) # small size for example's sake\n",
    "\n",
    "g = x -> ForwardDiff.gradient(f, x); # g = ∇f\n",
    "\n",
    "@show g(x)\n",
    "\n",
    "ForwardDiff.hessian(f, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep learning\n",
    "\n",
    "Classic MNIST number classification with Flux.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated\n",
    "# using CuArrays\n",
    "\n",
    "# Classify MNIST digits with a simple multi-layer-perceptron\n",
    "\n",
    "imgs = MNIST.images()\n",
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu\n",
    "\n",
    "labels = MNIST.labels()\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9) |> gpu\n",
    "\n",
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) |> gpu\n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 100)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM()\n",
    "\n",
    "# Train\n",
    "Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))\n",
    "@show accuracy(X, Y)\n",
    "# Test set accuracy\n",
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...) |> gpu\n",
    "tY = onehotbatch(MNIST.labels(:test), 0:9) |> gpu\n",
    "@show accuracy(tX, tY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = rand(1:length(MNIST.images(:test)))\n",
    "print(\"Prediction:\",argmax(tY[:,n])-1)\n",
    "heatmap(MNIST.images(:test)[n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep learning + Autodiff\n",
    "\n",
    "=> Scientific Machine learning\n",
    "\n",
    "http://www.stochasticlifestyle.com/the-essential-tools-of-scientific-machine-learning-scientific-ml/\n",
    "\n",
    "https://fluxml.ai/2019/03/05/dp-vs-rl.html\n",
    "\n",
    "https://fluxml.ai/2019/02/07/what-is-differentiable-programming.html\n",
    "\n",
    "https://www.youtube.com/watch?v=FGfx8CQHdQA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ecosystem\n",
    "\n",
    "And much more :\n",
    "\n",
    "- JuliaRobotics (real-time !)\n",
    "- Stats/Machine Learning\n",
    "- Web\n",
    "- GPU\n",
    "- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interop\n",
    "\n",
    "Interop possible avec Python, Matlab, R, Java, C/Fortran,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"PyCall\") # add python binding package\n",
    "\n",
    "using PyCall \n",
    "@pyimport math\n",
    "@show math.sin(math.pi / 4)\n",
    "@show sin(pi / 4) ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32661540"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call C\n",
    "t = ccall((:clock, \"libc.so.6\"), Int32, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Macros: code that transforms code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.071034 seconds (177.92 k allocations: 9.331 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8//9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @time macro inserts timing and memory profiling into expression, then evaluates, and prints\n",
    "@time f(2//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "exp(x::<b>Real</b>) in Base.Math at <a href=\"https://github.com/JuliaLang/julia/tree/55e36cc308b66d3472990a06b2797f9f9154ea0a/base/special/exp.jl#L73\" target=\"_blank\">special/exp.jl:73</a>"
      ],
      "text/plain": [
       "exp(x::Real) in Base.Math at special/exp.jl:73"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @which macro determines which function is called, provides link to source code on GitHub\n",
    "@which exp(π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "exp(z::<b>Complex</b>) in Base at <a href=\"https://github.com/JuliaLang/julia/tree/55e36cc308b66d3472990a06b2797f9f9154ea0a/base/complex.jl#L604\" target=\"_blank\">complex.jl:604</a>"
      ],
      "text/plain": [
       "exp(z::Complex) in Base at complex.jl:604"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which exp(π*im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Macros enable run-time code generation and transformation. \n",
    "\n",
    "Applications :\n",
    "\n",
    "  * generation and execution of boilerplate code\n",
    "  * run-time generation and optimization of algorithms, e.g. FFTW, ATLAS\n",
    "  * symbolic mathematics, automatic differentiation\n",
    "  * *all written like high-level Python, running like compiled C !!!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelism in Julia: just change the array type\n",
    "\n",
    "Some very trivial examples of Julia's built-in parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using Distributed\n",
    "#Pkg.add(\"DistributedArrays\")\n",
    "\n",
    "addprocs(4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "; cat codes/count_heads.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere include(\"codes/count_heads.jl\")\n",
    "\n",
    "a = @spawn count_heads(10000000)\n",
    "b = @spawn count_heads(10000000)\n",
    "fetch(a)+fetch(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parallel loops with reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nheads = @distributed (+) for i=1:200000000\n",
    "  Int(rand(Bool))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And more :\n",
    "- Distributed arrays\n",
    "- GPUArrays\n",
    "- TPUArrays ...\n",
    "- Nested Threading (PARTR)\n",
    "\n",
    "Just changing the behavior of the underlying structure can bring new hardware support for all packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Helpful materials\n",
    "\n",
    "     \n",
    "- Main site https://julialang.org/\n",
    "- Docs https://docs.julialang.org/en/v1/\n",
    "- Courses : https://juliaacademy.com/\n",
    "- Forum https://discourse.julialang.org/\n",
    "- Book https://benlauwens.github.io/ThinkJulia.jl/latest/book.html\n",
    "- Blog http://www.stochasticlifestyle.com/\n",
    "- All-in-one package : https://juliacomputing.com/products/juliapro.html\n",
    "- Try online  : https://juliabox.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code as a first-class citizen product of research\n",
    "\n",
    "- The (new version) Julia package manager has reproductibility at its core (each code project is linked to a deterministic set of dependencies)\n",
    "- Creating a Julia package comes with tools for documentation, unit testing, continuous integration\n",
    "- New scientific collaborations can be based on software (see the Github organizations such as JuliaDiff, JuliaStats, etc...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Food for thoughts\n",
    "\n",
    "- Cost and open source\n",
    "    - Matlab licences cost several 10K€ each year to some labs\n",
    "    - Julia (and Python and R) come for free but development is not free\n",
    "    - A part of Matlab costs could go to financing open source software that is critical for science (see e.g. https://bitbucket.org/paugier/etude-asso-pynumfr/src/default/etude_asso_python_sciences_fr.rst?fileviewer=file-view-default)\n",
    "- The combo C(++) low-level libraries and high level bindings (as Tensorflow, Keras...) lead to black box workflows..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "Julia\n",
    "* **Easy as Matlab, fast as Fortran, flexible as Python, deep as Lisp**\n",
    "*  Scientific computing, from interactive exploration to HPC\n",
    "*  Paradigms (multiple dispatch) that enforce collaboration\n",
    "\n",
    "Not covered\n",
    "* large-scale programming, development ecosystem, environments, debuggers, etc.\n",
    "* Abstract Types, compositions, ...\n",
    "* rough edges: plotting, static compilation  (not quite there), package loading times, young 1.x\n",
    "\n",
    "*Thanks* : the Julia community for most of the examples, xkcd\n",
    "\n",
    "  \n",
    "Julia website: http://www.julialang.org, this talk: https://github.com/raphbacher/julia-intro\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "489759160e55444a8c745a10fe92f24d",
   "lastKernelId": "889e0dea-92b8-4990-9810-4f5f2118a132"
  },
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
